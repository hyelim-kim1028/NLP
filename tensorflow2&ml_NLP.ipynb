{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2&ml_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOH4/gunZx1nus4fFia99L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyelim-kim1028/NLP/blob/main/tensorflow2%26ml_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K78R8svUe3vw"
      },
      "source": [
        "#텐서플로2와 머신러닝으로 시작하는 자연어처리 \n",
        "\n",
        "출판사: 위키북스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf9hOdBFfTHd"
      },
      "source": [
        "#01. 들어가며"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eXWi1QmeydX",
        "outputId": "4ea1962c-2028-4e26-9fb3-575cef95e663"
      },
      "source": [
        "# clone the git rep on colab <!git clone ~> \n",
        "!git clone https://github.com/hyelim-kim1028/tensorflow-ml-nlp-tf2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tensorflow-ml-nlp-tf2'...\n",
            "remote: Enumerating objects: 1715, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 1715 (delta 42), reused 9 (delta 5), pack-reused 1631\u001b[K\n",
            "Receiving objects: 100% (1715/1715), 201.17 MiB | 22.29 MiB/s, done.\n",
            "Resolving deltas: 100% (1032/1032), done.\n",
            "Checking out files: 100% (88/88), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox8ET_Lugakl",
        "outputId": "62b8ffee-6c88-4064-bf59-d9188681fb4a"
      },
      "source": [
        "# 필요 라이브버리 설치 <!pip install ~>  \n",
        "#!pip install -r requirements.txt\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.32.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDI5OYowwe2Y"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmnV8UOqfWu_"
      },
      "source": [
        "#02.자연어 처리 개발 준비\n",
        "\n",
        "- 텐서플로 \n",
        "- 사이킷런 \n",
        "- 자연어 토크나이징 도구\n",
        "- 그 밖의 라이브러리 (전처리) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gf-WR87_gUqv",
        "outputId": "429d67d6-b6f5-40a1-e2e7-d653bee968e8"
      },
      "source": [
        "# tf.keras.layers \n",
        "# y = f(Wx + b)\n",
        "\n",
        "W = tf.Variable(tf.random.uniform([5,10], -1.0, 1.0))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "y = tf.matmul(W, x) + b\n",
        "# NameError: name 'x' is not defined \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b2585bb78d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLbvaGLvxrMM"
      },
      "source": [
        "# Dense층 객체에 입력값 설정  \n",
        "#1. Dense객체 생성 및 입력값 설정 \n",
        "dense = tf.keras.layers.Dense(...)\n",
        "output = dense(input)\n",
        "\n",
        "#2. 객체 생성 시 입력값 설정 \n",
        "output = tf.keras.layers.Dense(...)(input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOkQcMIRgcgv"
      },
      "source": [
        "#Dense 층에 가중치, 편향 초기화 방법, 활성화 함수의 종류 옵션 설정 \n",
        "\n",
        "__init__(\n",
        "    units,\n",
        "    activation = None, # 활성화 함수 \n",
        "    use_bias = True,  #가중치 \n",
        "    kernel_initializer = 'glorot_uniform',# 가중치 초기화 \n",
        "    bias_initializer = 'zeros', # 편향 초기화 \n",
        "    kernel_regularizer = None, \n",
        "    bias_regularizer = None,\n",
        "    activity_regularizer = None, \n",
        "    kernel_constraint = None, \n",
        "    bias_constraint = None, \n",
        "    **kwargs \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAP6EYc5gcqe"
      },
      "source": [
        "# 신경망 생성 \n",
        "INPUT_SIZE = (20, 1)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
        "hidden = tf.keras.layers.Dense(units=10, activation = tf.nn.sigmoid)(inputs) #10의 노드 은닉층 \n",
        "output  = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden) #2개의 출력 노드 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJ1BYjNgcza"
      },
      "source": [
        "# tf.keras.layers.Dropout\n",
        "\n",
        "# 1. 객체 생성 후 다시 호출하면서 입력값 설정 \n",
        "dropout = tf.keras.layers.Dropout(...)\n",
        "output = dropout(input)\n",
        "\n",
        "# 2. 객체 생성 시 입력값 설정 \n",
        "output = tf.keras.layers.Dropout(...)(input)\n",
        "\n",
        "__init__(\n",
        "    rate, \n",
        "    noise_shape = None, \n",
        "    seed = None, \n",
        "    **kwargs \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSjuPeMIgc8Q"
      },
      "source": [
        "INPUT_SIZE = (20, 1)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
        "dropout = tf.keras.layers.Dropout(rate = 0.5)(inputs)\n",
        "\n",
        "# tf.keras.layers.dropout \n",
        "# 0.2 > 20%노드를 0으로 만든다 \n",
        "# tf.nn.dropout \n",
        "# 0.2 > 80%의 노드를 0으로 만든다 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIEW309ZgdEu"
      },
      "source": [
        "#dense층 신경망 구조에 드롭아웃 적용 \n",
        "\n",
        "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
        "dropout = tf.keras.layers.Dropout(rate=0.2)(input)\n",
        "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)\n",
        "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid )(hidden)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F633TMy05r4b"
      },
      "source": [
        "# 1. 객체 생성 후 다시 호출하면서 입력값 설정 \n",
        "conv1d = tf.keras.layers.Conv1D(...)\n",
        "output = conv1d(input)\n",
        "\n",
        "# 2. 객체 생성 시 입력값 설정 \n",
        "output = tf.keras.layers.Conv1D(...)(input)\n",
        "\n",
        "# 객체 생성 시 전달 인자 \n",
        "__init__(\n",
        "    filters, # 몇개의 필터 사용 \n",
        "    #conv1D는 필터의 가로 길이만 설정 #세로는 1D는 상관 없음 \n",
        "    kernel_size, #필터의 가로 길이 \n",
        "    strides = 1,\n",
        "    padding = 'valid',\n",
        "    data_format = 'channels_last',\n",
        "    dilation_rate = 1,\n",
        "    activation = None, \n",
        "    use_bias = True, \n",
        "    kernel_initializer = 'glorot_uniform',\n",
        "    bias_initializer = 'zeros',\n",
        "    kernel_regularizer = None, \n",
        "    bias_regularizer = None, \n",
        "    activity_regularizer = None, \n",
        "    kernel_constraint = None, \n",
        "    bias_constraint = None, \n",
        "    **kwargs \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn-vWkPEFR-9"
      },
      "source": [
        "# conv1D를 사용한 합성곱 신경망 \n",
        "\n",
        "INPUT_SIZE = (1,28,28)\n",
        "\n",
        "inputs = tf.keras.Input(shape = INPUT_SIZE)\n",
        "conv = tf.keras.layers.Conv1D(\n",
        "    filters = 10,\n",
        "    kernel_size = 3,\n",
        "    padding = 'same',\n",
        "    activation = tf.nn.relu\n",
        ")(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdwV-rbXFSjI"
      },
      "source": [
        "# dropout 적용 \n",
        "\n",
        "INPUT_SIZE = (1, 28, 28)\n",
        "\n",
        "inputs = tf.keras.Input(shape = INPUT_SIZE)\n",
        "dropout = tf.keras.layers.Dropout(rate = 0.2)(inputs)\n",
        "conv = tf.keras.layers.Conv1D(filters = 10, kernel_size = 3, padding = 'same', activation = tf.nn.relu)(dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTfFx1UgQurW"
      },
      "source": [
        "# tf.keras.layers.MaxPool1D \n",
        "# feature map의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용 \n",
        "# max pooling: 최댓값만 뽑아냄 #average pooling: 평균값만 뽑아냄 \n",
        "\n",
        "# MaxPool1D, MaxPool2D, MaxPool3D \n",
        "\n",
        "# 1. 객체 생성 후 apply 함수를 이용해 입력값 설정 \n",
        "max_pool = tf.keras.layers.MaxPool1D(...)\n",
        "max_pool.apply(input)\n",
        "\n",
        "# 2. 객체 생성 시 입력값 설정 \n",
        "max_pool = tf.keras.layers.MaxPool1D(...)(input)\n",
        "\n",
        "__init__(\n",
        "    pool_size = 2, #필터의 크기 \n",
        "    strides = None, # 적용할 스트라이드 값 \n",
        "    padding = 'valid', # same or valid \n",
        "    data_format = None, #channel_last = (batch, length, channels) #channel_first = (batch, channels, length) \n",
        "    **kwargs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Q0TXIlQy9r"
      },
      "source": [
        "# maxpooling, dropout 적용 \n",
        "\n",
        "INPUT_SIZE = (1, 28, 28)\n",
        "\n",
        "inputs = tf.keras.Input(shape = INPUT_SIZE)\n",
        "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
        "conv = tf.keras.layers.Conv1D(\n",
        "    filters = 10,\n",
        "    kernel_size = 3,\n",
        "    padding = 'same',\n",
        "    activation = tf.nn.relu\n",
        ")(input)\n",
        "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)\n",
        "flatten = tf.keras.layers.Flatten()(max_pool)\n",
        "hidden = tf.keras.layers.Dense(units=50, activation = tf.nn.relu)(flatten)\n",
        "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DILac89RY58T"
      },
      "source": [
        "- API clean up \n",
        "- Eager Execution \n",
        "- No more globals \n",
        "- Functions, not sessions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss3iW5KEjubT"
      },
      "source": [
        "#- model construction (Keras API) \n",
        "#  - Sequential API \n",
        "#  - Functional API \n",
        "#  - Functional/Sequential API \n",
        "#    +) Custom Layers \n",
        "#  - Subclassing (Custom Model) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb2n21t9Yjd5"
      },
      "source": [
        "# keras #Sequentail API # simpy Fully-connected layer \n",
        "\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "# sequential \n",
        "# stack 형에는 접합하지만, 복잡한 구조에는 어려움 \n",
        "# 다중 입력값 모델 (Multi-input models)\n",
        "# 다중 출력값 모델 (Multi-output models)\n",
        "# 공유 층을 활용하는 모델 (Models with shared layers)\n",
        "# 데이터 흐름이 순차적이지 않은 모델 (Models with non-sequential data flows)\n",
        "# Functional API or subclassing 방식 사용 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrzXmZPubj0_"
      },
      "source": [
        "# Functional API \n",
        "inputs = tf.keras.Input(shape=(32,)) # = tf.placeholder0\n",
        "x = layers.Dense(64, activation = 'relu')(inputs)\n",
        "x = layers.Dense(64, activation = 'relu')(x)\n",
        "predictions = layers.Dense(10, activation = 'softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AChog3PJQzPP"
      },
      "source": [
        "class CustomLayer(layers.layer):\n",
        "\n",
        "  def __init__(self, hidden_dimension, hidden_dimension2, output_dimension):\n",
        "    self.hidden_dimension = hidden_dimension \n",
        "    self.hidden_dimension2 = hidden_dimension2 \n",
        "    self.output_dimension = output_dimension \n",
        "    super(CustomLayer, self).__init__()\n",
        "\n",
        "  def build(self, input_shape): # 모델 가중치 \n",
        "    self.dense_layer1 = layers.Dense(self.hidden_dimension, activation = 'relu')\n",
        "    self.dense_layer2 = layers.Dense(self.hidden_dimension2, activation = 'relu')\n",
        "    self.dense_layer3 = layers.Dense(self.output_dimenstion, activation = 'softmax')\n",
        "\n",
        "  def call(self, inputs): # 층의 로직 정의 \n",
        "    x = self.dense_layer1(inputs)\n",
        "    x = self.dense_layer2(x)\n",
        "\n",
        "    return self.dense_layer3(x)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DYjSTA-fl_L"
      },
      "source": [
        "#sequential 모듈 활용 \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(CustomLayer(64, 64, 10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HvEmnLGh7sv"
      },
      "source": [
        "# Subclassing (Custom Model)\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, hidden_dimension, hidden_dimension2, output_dimension):\n",
        "    # 모델에 사용될 층과 변수 정의 \n",
        "    super(MyModel, self).__init__(name = 'my model')\n",
        "    self.dense_layer1 = layers.Dense(hidden_dimension, activation = 'relu')\n",
        "    self.dense_layer2 = layers.Dense(hidden_dimension2, activation = 'relu')\n",
        "    self.dense_layer3 = layers.Dense(output_dimension, activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # 모델 연산 진행 \n",
        "    x = self.dense_layer1(inputs)\n",
        "    x = self.dense_layer2(x)\n",
        "\n",
        "    return self.dense_layer3(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCPf7ueEkNPE"
      },
      "source": [
        "#모델 학습 \n",
        "\n",
        "1) keras 내장 API 활용 \n",
        "(i.e. model.fit(), model.evaluate(), model.predict())\n",
        "\n",
        "2) 학습, 검증, 예측 등 모든 과정을 GradientTape 객체를 활용해 직접 구현하는 방법 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk7FfVvUQzdF"
      },
      "source": [
        "# 내장 API를 활용하는 방법 \n",
        "\n",
        "# 1. 학습 과정 정의 \n",
        "# 손실 함수 (loss function), 옵티마이저 (optimizer), 평가 지표 (metric)\n",
        "\n",
        "#객체 형식 지정 \n",
        "model.compie(optimizer = tf.keras.optimizers.Adam(),\n",
        "             loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics = [tf.keras.metrics.Accuracy()])\n",
        "\n",
        "#문자열 형태 지정 \n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqD2zmNaQzow"
      },
      "source": [
        "model.fit(x_train, y_train, \n",
        "          batch_size = 64, \n",
        "          epochs = 3, \n",
        "          validation_data = (x_val, y_val))\n",
        "          # epoch 마다 검증 결과를 보기 위해서는 \n",
        "          # fit 함수의 검증 데이터를 추가로 넣으면 된다 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5iFZbCnQz2B"
      },
      "source": [
        "# 더미 데이터를 활용한 감정 분석 모델링 \n",
        "\n",
        "# 입력값: 단어 > 임베딩 벡터 \n",
        "# 백터 평균 > 하나의 백터 \n",
        "# 결과값: 시그모이드, 0~1 \n",
        "\n",
        "# 모델 구현 \n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "samples = ['너 오늘 이뻐 보인다',\n",
        "           '나는 오늘 기분이 더러워',\n",
        "           '끝내주는데, 좋은 일이 있나봐',\n",
        "           '나 좋은 일이 생겼어',\n",
        "           '아 오늘 진짜 짜증나',\n",
        "           '환상적인데, 정말 좋은거 같아']\n",
        "\n",
        "labels = [[1],[0],[1],[1],[0],[1]]\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1xn74YnQ0CD"
      },
      "source": [
        "# 모델 구축 및 모델 학습에 필요한 변수 정의 \n",
        "\n",
        "batch_size = 2\n",
        "num_epochs = 100 \n",
        "vocab_size = len(word_index) + 1\n",
        "# 모델 하이퍼 파라미터 (임베딩 층, 은닉층, 출력층)\n",
        "emb_size = 128 \n",
        "hidden_dimension= 256 \n",
        "output_dimension = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytPpn1kj75nA"
      },
      "source": [
        "# Sequential API 를 활용한 심층 신경망 모델 \n",
        "\n",
        "#방법 1 # Sequential 객체 생성 후 각 층 추가 \n",
        "model = tf.keras.Sequential() \n",
        "model.add(layers.Embedding(vocab_size, emb_size, input_length = 4))\n",
        "model.add(layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)))\n",
        "model.add(layers.Dense(hidden_dimension, activation = 'relu'))\n",
        "model.add(layers.Dense(output_dimension, activation = 'sigmoid'))\n",
        "\n",
        "# 방법 2 # 객체 생성 시 인자로 사용할 층을 순차적으로 리스트로 만들어서 전달 \n",
        "model = tf.keras.Sequential([\n",
        "layers.Embedding(vocab_size, emb_size, input_length = 4),\n",
        "layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)),\n",
        "layers.Dense(hidden_dimension, activation = 'relu'),\n",
        "layers.Dense(output_dimension, activation = 'sigmoid')                             \n",
        "])\n",
        "\n",
        "# 입력값 embdding 층 추가 \n",
        "# 임베딩 된 단어의 백터 평균 > lambda층 사용 \n",
        "# 0~1 사이 > sigmoid 사용 \n",
        "\n",
        "#모델 컴파일 메서드 # 학습 과정 정의 \n",
        "# 옵티마이저 > Adam 최적화 \n",
        "# 이진분류 > binary cross-entropy \n",
        "# 모델 측정 지표 > accuracy \n",
        "\n",
        "model.compile(optimizer =  tf.keras.optimizers.Adam(0.001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy']) \n",
        "\n",
        "# fit 메서드 # 학습 진행 \n",
        "model.fit(input_sequences, lables, epochs = num_epochs, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAm546eA-zu6"
      },
      "source": [
        "# Functional API, Subclassing \n",
        "\n",
        "inputs = layers.Input(shape = (4,))\n",
        "embed_output = layers.Embedding(vocab_size, emb_size)(inputs)\n",
        "pooled_output = tf.reduce_mean(embed_output, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq9Vi8JFMAFJ"
      },
      "source": [
        "tensorflow 공식 API 문서\n",
        "\n",
        "www.tensorflow.org/api_docs/python/tf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xS1cfm5FSsS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_QMmcNgFS0g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po4eLdUNfY8h"
      },
      "source": [
        "#03. 자연어 처리 개요 \n",
        "- 단어표현 \n",
        "- 텍스트 분류\n",
        "- 텍스트 유사도 \n",
        "- 자연어 생성 \n",
        "- 기계 이해 \n",
        "- 데이터 이해하기 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEVOsV7cgVe-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ct5vwytfwsn"
      },
      "source": [
        "#04.텍스트 분류\n",
        "\n",
        "- 영어 텍스트 분류 \n",
        "- 한글 텍스트 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfa-g8jygXBq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzVxD1lgfxas"
      },
      "source": [
        "#05.텍스트 유사도\n",
        "- 문제 소개 \n",
        "- 데이터 분석과 전처리 \n",
        "- 모델링 \n",
        "- 정리 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6vDrPeUgYFl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BlLhUVifx5u"
      },
      "source": [
        "#06.챗봇 만들기\n",
        "- 데이터 소개 \n",
        "- 데이터 분석\n",
        "- 시퀀스 투 시퀀스 모델 \n",
        "- 트랜스포머 모델 \n",
        "- 정리 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n4ES4wOgSwb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-GbV7ufyWB"
      },
      "source": [
        "#07.사전 학습 모델 \n",
        "- 버트 \n",
        "- 버트를 활용한 미세 조정 학습 \n",
        "- GPT \n",
        "- GPT2를 활용한 미세 조정 학습 \n",
        "- 정리 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCBrW-jEgRab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0KkE5XRgR5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpU7cqQOQveA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqtJeaO--ZzU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}